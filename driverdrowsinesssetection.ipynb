{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPP/sgIDxn1OyVEl8uaZpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSukeerthi/internship/blob/main/driverdrowsinesssetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXbFDHyWLbF_",
        "outputId": "c6a3bfd0-d695-49bd-c1c0-69d3c290a690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0PkVRC6L0eZ",
        "outputId": "4a65d409-07fa-4923-f639-3d4a63f15569"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.24)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.21 sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoZ24fuLMRO8",
        "outputId": "39e12b47-aec4-4d3a-b2d4-0c35ee1fa993"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    permission = input(\"Allow camera access? (y/n): \")\n",
        "    if permission.lower() == 'y':\n",
        "        break\n",
        "    elif permission.lower() == 'n':\n",
        "        print(\"Camera access denied. Exiting calibration.\")\n",
        "        # You might want to consider using 'exit()' here instead of returning if you intend to completely terminate the script\n",
        "        exit()  # Or 'return None, None, None, None' if it's within a function\n",
        "    else:\n",
        "        print(\"Invalid input. Please enter 'y' or 'n'.\")\n",
        "\n",
        "cap = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFsfURZjyxXB",
        "outputId": "6f5f34de-76eb-4e81-8a66-3450c95b9cf9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allow camera access? (y/n): y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "        lighting_input = input(\"Is the lighting sufficient? (y/n): \")\n",
        "        if lighting_input.lower() == 'y':\n",
        "            break\n",
        "        elif lighting_input.lower() == 'n':\n",
        "            print(\"Please adjust lighting conditions before proceeding.\")\n",
        "        else:\n",
        "            print(\"Invalid input. Please enter 'y' or 'n'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLd_LB5-zFyU",
        "outputId": "8f88a737-756f-47a9-ac79-bddeb67e05f6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is the lighting sufficient? (y/n): y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "def distance(p1, p2):\n",
        "    ''' Calculate distance between two points\n",
        "    :param p1: First Point\n",
        "    :param p2: Second Point\n",
        "    :return: Euclidean distance between the points. (Using only the x and y coordinates).\n",
        "    '''\n",
        "    return (((p1[:2] - p2[:2])**2).sum())**0.5\n",
        "\n",
        "def eye_aspect_ratio(landmarks, eye):\n",
        "    ''' Calculate the ratio of the eye length to eye width.\n",
        "    :param landmarks: Face Landmarks returned from FaceMesh MediaPipe model\n",
        "    :param eye: List containing positions which correspond to the eye\n",
        "    :return: Eye aspect ratio value\n",
        "    '''\n",
        "    N1 = distance(landmarks[eye[1][0]], landmarks[eye[1][1]])\n",
        "    N2 = distance(landmarks[eye[2][0]], landmarks[eye[2][1]])\n",
        "    N3 = distance(landmarks[eye[3][0]], landmarks[eye[3][1]])\n",
        "    D = distance(landmarks[eye[0][0]], landmarks[eye[0][1]])\n",
        "    return (N1 + N2 + N3) / (3 * D)\n",
        "\n",
        "def eye_feature(landmarks):\n",
        "    ''' Calculate the eye feature as the average of the eye aspect ratio for the two eyes\n",
        "    :param landmarks: Face Landmarks returned from FaceMesh MediaPipe model\n",
        "    :return: Eye feature value\n",
        "    '''\n",
        "    return (eye_aspect_ratio(landmarks, left_eye) + \\\n",
        "    eye_aspect_ratio(landmarks, right_eye))/2\n",
        "\n",
        "def mouth_feature(landmarks):\n",
        "    ''' Calculate mouth feature as the ratio of the mouth length to mouth width\n",
        "    :param landmarks: Face Landmarks returned from FaceMesh MediaPipe model\n",
        "    :return: Mouth feature value\n",
        "    '''\n",
        "    N1 = distance(landmarks[mouth[1][0]], landmarks[mouth[1][1]])\n",
        "    N2 = distance(landmarks[mouth[2][0]], landmarks[mouth[2][1]])\n",
        "    N3 = distance(landmarks[mouth[3][0]], landmarks[mouth[3][1]])\n",
        "    D = distance(landmarks[mouth[0][0]], landmarks[mouth[0][1]])\n",
        "    return (N1 + N2 + N3)/(3*D)\n",
        "\n",
        "def pupil_circularity(landmarks, eye):\n",
        "    ''' Calculate pupil circularity feature.\n",
        "    :param landmarks: Face Landmarks returned from FaceMesh MediaPipe model\n",
        "    :param eye: List containing positions which correspond to the eye\n",
        "    :return: Pupil circularity for the eye coordinates\n",
        "    '''\n",
        "    perimeter = distance(landmarks[eye[0][0]], landmarks[eye[1][0]]) + \\\n",
        "            distance(landmarks[eye[1][0]], landmarks[eye[2][0]]) + \\\n",
        "            distance(landmarks[eye[2][0]], landmarks[eye[3][0]]) + \\\n",
        "            distance(landmarks[eye[3][0]], landmarks[eye[0][1]]) + \\\n",
        "            distance(landmarks[eye[0][1]], landmarks[eye[3][1]]) + \\\n",
        "            distance(landmarks[eye[3][1]], landmarks[eye[2][1]]) + \\\n",
        "            distance(landmarks[eye[2][1]], landmarks[eye[1][1]]) + \\\n",
        "            distance(landmarks[eye[1][1]], landmarks[eye[0][0]])\n",
        "    area = math.pi * ((distance(landmarks[eye[1][0]], landmarks[eye[3][1]]) * 0.5) ** 2)\n",
        "    return (4*math.pi*area)/(perimeter**2)\n",
        "\n",
        "def pupil_feature(landmarks):\n",
        "    ''' Calculate the pupil feature as the average of the pupil circularity for the two eyes\n",
        "    :param landmarks: Face Landmarks returned from FaceMesh MediaPipe model\n",
        "    :return: Pupil feature value\n",
        "    '''\n",
        "    return (pupil_circularity(landmarks, left_eye) + \\\n",
        "        pupil_circularity(landmarks, right_eye))/2\n",
        "\n",
        "def run_face_mp(image):\n",
        "    ''' Get face landmarks using the FaceMesh MediaPipe model.\n",
        "    Calculate facial features using the landmarks.\n",
        "    :param image: Image for which to get the face landmarks\n",
        "    :return: Feature 1 (Eye), Feature 2 (Mouth), Feature 3 (Pupil), \\\n",
        "        Feature 4 (Combined eye and mouth feature), image with mesh drawings\n",
        "    '''\n",
        "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
        "    image.flags.writeable = False\n",
        "    results = face_mesh.process(image)\n",
        "\n",
        "    image.flags.writeable = True\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        landmarks_positions = []\n",
        "        # assume that only face is present in the image\n",
        "        for _, data_point in enumerate(results.multi_face_landmarks[0].landmark):\n",
        "            landmarks_positions.append([data_point.x, data_point.y, data_point.z]) # saving normalized landmark positions\n",
        "        landmarks_positions = np.array(landmarks_positions)\n",
        "        landmarks_positions[:, 0] *= image.shape[1]\n",
        "        landmarks_positions[:, 1] *= image.shape[0]\n",
        "\n",
        "        # draw face mesh over image\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "                mp_drawing.draw_landmarks(\n",
        "                    image=image,\n",
        "                    landmark_list=face_landmarks,\n",
        "                    connections=mp_face_mesh.FACE_CONNECTIONS,\n",
        "                    landmark_drawing_spec=drawing_spec,\n",
        "                    connection_drawing_spec=drawing_spec)\n",
        "\n",
        "        ear = eye_feature(landmarks_positions)\n",
        "        mar = mouth_feature(landmarks_positions)\n",
        "        puc = pupil_feature(landmarks_positions)\n",
        "        moe = mar/ear\n",
        "    else:\n",
        "        ear = -1000\n",
        "        mar = -1000\n",
        "        puc = -1000\n",
        "        moe = -1000\n",
        "\n",
        "    return ear, mar, puc, moe, image\n",
        "def calibrate(calib_frame_count=25):\n",
        "    ''' Perform clibration. Get features for the neutral position.\n",
        "    :param calib_frame_count: Image frames for which calibration is performed. Default Vale of 25.\n",
        "    :return: Normalization Values for feature 1, Normalization Values for feature 2, \\\n",
        "        Normalization Values for feature 3, Normalization Values for feature 4\n",
        "    '''\n",
        "    ears = []\n",
        "    mars = []\n",
        "    pucs = []\n",
        "    moes = []\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            print(\"Ignoring empty camera frame.\")\n",
        "            continue\n",
        "\n",
        "        ear, mar, puc, moe, image = run_face_mp(image)\n",
        "\n",
        "        # Check if face is detected before appending features\n",
        "        if ear != -1000:\n",
        "            ears.append(ear)\n",
        "            mars.append(mar)\n",
        "            pucs.append(puc)\n",
        "            moes.append(moe)\n",
        "        else:\n",
        "            print(\"Face not detected in calibration frame.\") # Print message when face is not detected\n",
        "\n",
        "\n",
        "        cv2.putText(image, \"Calibration\", (int(0.02*image.shape[1]), int(0.14*image.shape[0])),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 2)\n",
        "        cv2.imshow('MediaPipe FaceMesh', image)\n",
        "        if cv2.waitKey(5) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "        if len(ears) >= calib_frame_count:\n",
        "            break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    cap.release()\n",
        "\n",
        "    # Check if any features were captured\n",
        "    if not ears: # If ears list is empty, it means no faces were detected\n",
        "        print(\"Error: No faces detected during calibration. Please check camera and lighting.\")\n",
        "        return None, None, None, None # Return None values to indicate calibration failure\n",
        "\n",
        "    ears = np.array(ears)\n",
        "    mars = np.array(mars)\n",
        "    pucs = np.array(pucs)\n",
        "    moes = np.array(moes)\n",
        "    return [ears.mean(), ears.std()], [mars.mean(), mars.std()],  \\\n",
        "        [pucs.mean(), pucs.std()], [moes.mean(), moes.std()]\n",
        "\n",
        "def get_classification(input_data):\n",
        "    ''' Perform classification over the facial  features.\n",
        "    :param input_data: List of facial features for 20 frames\n",
        "    :return: Alert / Drowsy state prediction\n",
        "    '''\n",
        "    model_input = []\n",
        "    model_input.append(input_data[:5])\n",
        "    model_input.append(input_data[3:8])\n",
        "    model_input.append(input_data[6:11])\n",
        "    model_input.append(input_data[9:14])\n",
        "    model_input.append(input_data[12:17])\n",
        "    model_input.append(input_data[15:])\n",
        "    model_input = torch.FloatTensor(np.array(model_input))\n",
        "    preds = torch.sigmoid((model_input)).gt(0.5).int().data.numpy()\n",
        "    return int(preds.sum() >= 5)\n",
        "\n",
        "def infer(ears_norm, mars_norm, pucs_norm, moes_norm):\n",
        "    ''' Perform inference.\n",
        "    :param ears_norm: Normalization values for eye feature\n",
        "    :param mars_norm: Normalization values for mouth feature\n",
        "    :param pucs_norm: Normalization values for pupil feature\n",
        "    :param moes_norm: Normalization values for mouth over eye feature.\n",
        "    '''\n",
        "    ear_main = 0\n",
        "    mar_main = 0\n",
        "    puc_main = 0\n",
        "    moe_main = 0\n",
        "    decay = 0.9 # use decay to smoothen the noise in feature values\n",
        "\n",
        "    label = None\n",
        "\n",
        "    input_data = []\n",
        "    frame_before_run = 0\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            print(\"Ignoring empty camera frame.\")\n",
        "            continue\n",
        "\n",
        "        ear, mar, puc, moe, image = run_face_mp(image)\n",
        "        if ear != -1000:\n",
        "            ear = (ear - ears_norm[0])/ears_norm[1]\n",
        "            mar = (mar - mars_norm[0])/mars_norm[1]\n",
        "            puc = (puc - pucs_norm[0])/pucs_norm[1]\n",
        "            moe = (moe - moes_norm[0])/moes_norm[1]\n",
        "            if ear_main == -1000:\n",
        "                ear_main = ear\n",
        "                mar_main = mar\n",
        "                puc_main = puc\n",
        "                moe_main = moe\n",
        "            else:\n",
        "                ear_main = ear_main*decay + (1-decay)*ear\n",
        "                mar_main = mar_main*decay + (1-decay)*mar\n",
        "                puc_main = puc_main*decay + (1-decay)*puc\n",
        "                moe_main = moe_main*decay + (1-decay)*moe\n",
        "        else:\n",
        "            ear_main = -1000\n",
        "            mar_main = -1000\n",
        "            puc_main = -1000\n",
        "            moe_main = -1000\n",
        "\n",
        "        if len(input_data) == 20:\n",
        "            input_data.pop(0)\n",
        "        input_data.append([ear_main, mar_main, puc_main, moe_main])\n",
        "\n",
        "        frame_before_run += 1\n",
        "        if frame_before_run >= 15 and len(input_data) == 20:\n",
        "            frame_before_run = 0\n",
        "            label = get_classification(input_data)\n",
        "            print ('got label ', label)\n",
        "\n",
        "        cv2.putText(image, \"EAR: %.2f\" %(ear_main), (int(0.02*image.shape[1]), int(0.07*image.shape[0])),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "        cv2.putText(image, \"MAR: %.2f\" %(mar_main), (int(0.27*image.shape[1]), int(0.07*image.shape[0])),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "        cv2.putText(image, \"PUC: %.2f\" %(puc_main), (int(0.52*image.shape[1]), int(0.07*image.shape[0])),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "        cv2.putText(image, \"MOE: %.2f\" %(moe_main), (int(0.77*image.shape[1]), int(0.07*image.shape[0])),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "        if label is not None:\n",
        "            if label == 0:\n",
        "                color = (0, 255, 0)\n",
        "            else:\n",
        "                color = (0, 0, 255)\n",
        "            cv2.putText(image, \"%s\" %(states[label]), (int(0.02*image.shape[1]), int(0.2*image.shape[0])),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 2)\n",
        "\n",
        "        cv2.imshow('MediaPipe FaceMesh', image)\n",
        "        if cv2.waitKey(5) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    cap.release()\n",
        "\n",
        "\n",
        "right_eye = [[33, 133], [160, 144], [159, 145], [158, 153]] # right eye landmark positions\n",
        "left_eye = [[263, 362], [387, 373], [386, 374], [385, 380]] # left eye landmark positions\n",
        "mouth = [[61, 291], [39, 181], [0, 17], [269, 405]] # mouth landmark coordinates\n",
        "states = ['alert', 'drowsy']\n",
        "\n",
        "# Declaring FaceMesh model\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    min_detection_confidence=0.3, min_tracking_confidence=0.8)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
        "\n",
        "print ('Starting calibration. Please be in neutral state')\n",
        "time.sleep(1)\n",
        "ears_norm, mars_norm, pucs_norm, moes_norm = calibrate()\n",
        "\n",
        "print ('Starting main application')\n",
        "time.sleep(1)\n",
        "infer(ears_norm, mars_norm, pucs_norm, moes_norm)\n",
        "\n",
        "face_mesh.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DXjPtxXxx1j",
        "outputId": "f496899b-d681-4240-98a4-d533a482ee5f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting calibration. Please be in neutral state\n",
            "Error: No faces detected during calibration. Please check camera and lighting.\n",
            "Starting main application\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The provided code is not Python code.  It appears to be a shell command.\n",
        "# If you want to execute it in a shell, you should prefix it with an exclamation mark (!).\n",
        "# For example: !check camera\n",
        "\n",
        "# If you intend to use a Python library to check a camera, you'll need to\n",
        "# provide code that uses that library, and I will help correct any errors."
      ],
      "metadata": {
        "id": "P7h1mhPP0vfJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "        lighting_input = input(\"Is the lighting sufficient? (y/n): \")\n",
        "        if lighting_input.lower() == 'y':\n",
        "            break\n",
        "        elif lighting_input.lower() == 'n':\n",
        "            print(\"Please adjust lighting conditions before proceeding.\")\n",
        "        else:\n",
        "            print(\"Invalid input. Please enter 'y' or 'n'.\")\n",
        "\n",
        "        cap = cv2.VideoCapture(0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRB7wqZz1F4T",
        "outputId": "47dd787f-598f-4ef3-cf6e-85d706903e16"
      },
      "execution_count": 40,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is the lighting sufficient? (y/n): n\n",
            "Please adjust lighting conditions before proceeding.\n",
            "Is the lighting sufficient? (y/n): 11\n",
            "Invalid input. Please enter 'y' or 'n'.\n",
            "Is the lighting sufficient? (y/n): y\n"
          ]
        }
      ]
    }
  ]
}